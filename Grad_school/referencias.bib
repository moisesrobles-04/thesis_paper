








% ____Official references________

@article{2020t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}


@INPROCEEDINGS{8622504,
  author={Garzón-Alfonso, Cristian C. and Rodríguez-Martínez, Manuel},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)}, 
  title={Twitter Health Surveillance (THS) System}, 
  year={2018},
  volume={},
  number={},
  pages={1647-1654},
  keywords={Twitter;Big Data;Tools;Diseases;Metadata;big data analytics;deep learning;disease detection},
  doi={10.1109/BigData.2018.8622504}}

@INPROCEEDINGS{9581175,
  author={Villanueva-Vega, Danny and Rodriguez-Martinez, Manuel},
  booktitle={2021 IEEE International Conference on Digital Health (ICDH)}, 
  title={Finding Similar Tweets in Health Related Topics}, 
  year={2021},
  volume={},
  number={},
  pages={184-190},
  keywords={Training;Social networking (online);Computational modeling;Data models;Real-time systems;Classification algorithms;Electronic healthcare;Deep Learning;tweets;similarity},
  doi={10.1109/ICDH52753.2021.00033}}

@article{9906925,
  author={Yilmaz, Tolga and Ulusoy, {\"O}zg{\"u}r},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Misinformation Propagation in Online Social Networks: Game Theoretic and Reinforcement Learning Approaches}, 
  year={2023},
  volume={10},
  number={6},
  pages={3321-3332},
  keywords={Games;Fake news;Social networking (online);Costs;Reinforcement learning;Receivers;Mathematical models;Cooperative systems;Cooperative games;misinformation propagation;online social networks (OSNs);reinforcement learning (RL)},
  doi={10.1109/TCSS.2022.3208793}}

@INPROCEEDINGS{10100054,
  author={Harbola, Aditya and Manchanda, Mahesh and Negi, Deepti},
  booktitle={2023 International Conference on Innovative Data Communication Technologies and Application (ICIDCA)}, 
  title={Misinformation classification using LSTM and BERT model}, 
  year={2023},
  volume={},
  number={},
  pages={1073-1077},
  keywords={Deep learning;Computational modeling;Bit error rate;Knowledge discovery;Information age;Natural language processing;Data models;Misinformation;Machine learning;LSTM;BERT},
  doi={10.1109/ICIDCA56705.2023.10100054}}

@INPROCEEDINGS{10455990,
  author={Singh, Paras Nath and Talasila, Sreya and Banakar, Shivaraj Veerappa},
  booktitle={2023 IEEE International Conference on ICT in Business Industry \& Government (ICTBIG)}, 
  title={Analyzing Embedding Models for Embedding Vectors in Vector Databases}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  keywords={Analytical models;Databases;Face recognition;Vectors;Natural language processing;Data models;Behavioral sciences;Artificial Intelligence;Density estimates;Nearest Neighbor;Neural Networks;Vector databases;Vector Embeddings;Vector indices;VectorDB},
  doi={10.1109/ICTBIG59752.2023.10455990}}

@INPROCEEDINGS{10683437,
  author={Sun, Tienlan and Somalwar, Anaiy and Chan, Hinson},
  booktitle={2024 IEEE 99th Vehicular Technology Conference (VTC2024-Spring)}, 
  title={Multimodal Retrieval Augmented Generation Evaluation Benchmark}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  keywords={Measurement;Industries;System performance;Benchmark testing;Feature extraction;Question answering (information retrieval);Noise robustness;Artificial Intelligence;Machine Learning;Large Language Models;Retrieval Augmented Generation},
  doi={10.1109/VTC2024-Spring62846.2024.10683437}}


@article{article_vaccine,
author = {Islam, Md Saiful and Kamal, Abu-Hena and Kabir, Alamgir and Southern, Dorothy and Khan, Sazzad and Hasan, S.M.Murshid and Sarkar, Tonmoy and Sharmin, Shayla and Das, Shiuli and Roy, Tuhin and Harun, Md Golam Dostogir and Chughtai, Abrar and Homaira, Nusrat and Seale, Holly},
year = {2021},
month = {05},
pages = {},
title = {COVID-19 vaccine rumors and conspiracy theories: The need for cognitive inoculation against misinformation to improve vaccine adherence}
}

@article{article,
author = {T, Sadiq and Mathew, Saji},
year = {2022},
month = {05},
pages = {1-15},
title = {The disaster of misinformation: a review of research in social media},
volume = {13},
journal = {International Journal of Data Science and Analytics},
doi = {10.1007/s41060-022-00311-6}
}

@inproceedings{Ayoobi_2023, series={HT ’23},
   title={The Looming Threat of Fake and LLM-generated LinkedIn Profiles: Challenges and Opportunities for Detection and Prevention},
   url={http://dx.doi.org/10.1145/3603163.3609064},
   DOI={10.1145/3603163.3609064},
   booktitle={Proceedings of the 34th ACM Conference on Hypertext and Social Media},
   publisher={ACM},
   author={Ayoobi, Navid and Shahriar, Sadat and Mukherjee, Arjun},
   year={2023},
   month=sep, collection={HT ’23} }

@misc{bge_embedding,
	title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, 
	author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},
	year={2023},
	eprint={2309.07597},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@article{bioinformatics,
    author = {Comeau, Donald C and Wei, Chih-Hsuan and Islamaj Doğan, Rezarta and Lu, Zhiyong},
    title = "{PMC text mining subset in BioC: about three million full-text articles and growing}",
    journal = {Bioinformatics},
    volume = {35},
    number = {18},
    pages = {3533-3535},
    year = {2019},
    month = {01},
    abstract = "{Interest in text mining full-text biomedical research articles is growing. To facilitate automated processing of nearly 3 million full-text articles (in PubMed Central® Open Access and Author Manuscript subsets) and to improve interoperability, we convert these articles to BioC, a community-driven simple data structure in either XML or JavaScript Object Notation format for conveniently sharing text and annotations.The resultant articles can be downloaded via both File Transfer Protocol for bulk access and a Web API for updates or a more focused collection. Since the availability of the Web API in 2017, our BioC collection has been widely used by the research community.https://www.ncbi.nlm.nih.gov/research/bionlp/APIs/BioC-PMC/.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btz070},
    url = {https://doi.org/10.1093/bioinformatics/btz070},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/35/18/3533/48975610/bioinformatics\_35\_18\_3533.pdf},
}

@misc{chroma,
title={The AI-native open-source embedding database},
author={Chroma},
year = {2022},
url = {https://www.trychroma.com/},
note = {accessed: 04.27.2024},
}

% Not in use
@misc{chung2022scalinginstructionfinetunedlanguagemodels,
      title={Scaling Instruction-Finetuned Language Models}, 
      author={Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
      year={2022},
      eprint={2210.11416},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.11416}, 
}
%

@misc{coviddata,
	title={COVID-19 Fake News Dataset},
	url={https://www.kaggle.com/datasets/arashnic/covid19-fake-news/data?select=NewsFakeCOVID-19.csv},
	publisher={Kaggle},
	author={M\"obius},
	month={October},
	year={2023}
}

@misc{covidunesco,
	title={Localized Misinformation in a Global Pandemic: Report on COVID-19 Narratives around the World},
	url={https://esoc.princeton.edu/publications/localized-misinformation-global-pandemic-report-covid-19-narratives-around-world},
	publisher={Empirical Study of Conflict, Princeton University},
	author={Samikshya Siwakoti and Kamya Yadav and Isra Thange and Nicola Bariletto and Luca Zanotti and Alaa Ghoneim and Jacob N.},
	month = {March},
	year={2021},
	pages={1-68}
}


@article{DBLP:journals/corr/abs-1810-04805,
  author       = {Jacob Devlin and
                  Ming{-}Wei Chang and
                  Kenton Lee and
                  Kristina Toutanova},
  title        = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                  Understanding},
  journal      = {CoRR},
  volume       = {abs/1810.04805},
  year         = {2018},
  url          = {http://arxiv.org/abs/1810.04805},
  eprinttype    = {arXiv},
  eprint       = {1810.04805},
  timestamp    = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2005-14165,
  author       = {Tom B. Brown and
                  Benjamin Mann and
                  Nick Ryder and
                  Melanie Subbiah and
                  Jared Kaplan and
                  Prafulla Dhariwal and
                  Arvind Neelakantan and
                  Pranav Shyam and
                  Girish Sastry and
                  Amanda Askell and
                  Sandhini Agarwal and
                  Ariel Herbert{-}Voss and
                  Gretchen Krueger and
                  Tom Henighan and
                  Rewon Child and
                  Aditya Ramesh and
                  Daniel M. Ziegler and
                  Jeffrey Wu and
                  Clemens Winter and
                  Christopher Hesse and
                  Mark Chen and
                  Eric Sigler and
                  Mateusz Litwin and
                  Scott Gray and
                  Benjamin Chess and
                  Jack Clark and
                  Christopher Berner and
                  Sam McCandlish and
                  Alec Radford and
                  Ilya Sutskever and
                  Dario Amodei},
  title        = {Language Models are Few-Shot Learners},
  journal      = {CoRR},
  volume       = {abs/2005.14165},
  year         = {2020},
  url          = {https://arxiv.org/abs/2005.14165},
  eprinttype    = {arXiv},
  eprint       = {2005.14165},
  timestamp    = {Thu, 25 May 2023 10:38:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2105-00813,
  author       = {Anton Chernyavskiy and
                  Dmitry Ilvovsky and
                  Preslav Nakov},
  title        = {Transformers: "The End of History" for NLP?},
  journal      = {CoRR},
  volume       = {abs/2105.00813},
  year         = {2021},
  url          = {https://arxiv.org/abs/2105.00813},
  eprinttype    = {arXiv},
  eprint       = {2105.00813},
  timestamp    = {Wed, 12 May 2021 15:54:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2105-00813.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@Article{encyclopedia3040099,
AUTHOR = {Benaissa Pedriza, Samia},
TITLE = {Disinformation Perception by Digital and Social Audiences: Threat Awareness, Decision-Making and Trust in Media Organizations},
JOURNAL = {Encyclopedia},
VOLUME = {3},
YEAR = {2023},
NUMBER = {4},
PAGES = {1387--1400},
URL = {https://www.mdpi.com/2673-8392/3/4/99},
ISSN = {2673-8392},
ABSTRACT = {The effects of disinformation in the media and social networks have been extensively studied from the perspective of reception studies. However, the perception of this media phenomenon expressed by different types of audiences in distant geographic locations and with different media cultures has hardly been addressed by experts. This theoretical review study aims to analyze the relationship between the actual level of disinformation and the perception expressed by the audiences themselves. The results of the study reveal, firstly, that users of social networks and digital media do not perceive being surrounded by an excessively worrying volume of disinformation, a fact that contrasts with the data recorded, which are visibly higher. This situation reveals that the audience tends to normalize disinformation, which is intensively consumed on a daily basis and does not seem to worry the public in general terms, although some differences can be detected depending on variables such as gender, age or education. On the other hand, paradoxically, audiences visibly express rejection attitudes towards the channels that disseminate false information, with media outlets being the least trusted, despite recognizing that social networks are the place where more disinformation is generated and circulated at the same time.},
DOI = {10.3390/encyclopedia3040099}
}


@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}


@inproceedings{inproceedings,
author = {Deng, Xiang and Bashlovkina, Vasilisa and Han, Feng and Baumgartner, Simon and Bendersky, Michael},
year = {2023},
month = {04},
pages = {1014-1019},
title = {LLMs to the Moon? Reddit Market Sentiment Analysis with Large Language Models},
doi = {10.1145/3543873.3587605}
}

@misc{jiang2023mistral7b,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06825}, 
}

@misc{han2023comprehensivesurveyvectordatabase,
      title={A Comprehensive Survey on Vector Database: Storage and Retrieval Technique, Challenge}, 
      author={Yikun Han and Chunjiang Liu and Pengfei Wang},
      year={2023},
      eprint={2310.11703},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2310.11703}, 
}

@misc{huggingface,
  title = {{Hugging Face – The AI community building the future},
  url = {\url{https://huggingface.co}},
  note = {Accessed: 2024-10-18}
}

@misc{jin2023rethinkinglearningratetuning,
      title={Rethinking Learning Rate Tuning in the Era of Large Language Models}, 
      author={Hongpeng Jin and Wenqi Wei and Xuyu Wang and Wenbin Zhang and Yanzhao Wu},
      year={2023},
      eprint={2309.08859},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2309.08859}, 
}

@misc{koh2023groundinglanguagemodelsimages,
      title={Grounding Language Models to Images for Multimodal Inputs and Outputs}, 
      author={Jing Yu Koh and Ruslan Salakhutdinov and Daniel Fried},
      year={2023},
      eprint={2301.13823},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2301.13823}, 
}

@misc{lewis2019bartdenoisingsequencetosequencepretraining,
      title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension}, 
      author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
      year={2019},
      eprint={1910.13461},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.13461}, 
}

@misc{liu2019robertarobustlyoptimizedbert,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1907.11692}, 
}

@misc{naveed2024comprehensiveoverviewlargelanguage,
      title={A Comprehensive Overview of Large Language Models}, 
      author={Humza Naveed and Asad Ullah Khan and Shi Qiu and Muhammad Saqib and Saeed Anwar and Muhammad Usman and Naveed Akhtar and Nick Barnes and Ajmal Mian},
      year={2024},
      eprint={2307.06435},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.06435}, 
}

@misc{ollama,
  title = {{Get up and running with large language models.},
  url = {\url{https://ollama.com}},
  note = {Accessed: 2024-09-29}
}

@misc{openai,
  title = {{OpenAI},
  url = {\url{https://openai.com}},
  note = {Accessed: 2024-09-20}
}

@misc{pgvector,
	title={pgvector: Open-source vector similarity search for Postgres},
	author={pgvector},
	year={2024},
	url={https://github.com/pgvector/pgvector},
	note={accessed: 10.1.2024},
}

@misc{pubmed,
  title = {{PubMed - National Library of Medicine},
  url = {\url{https://pubmed.ncbi.nlm.nih.gov}},
  note = {Accessed: 2024-05-10}
}

@article{social_fact,
doi={10.1126/sciadv.abo6169},
author = {Ziv Epstein  and Nathaniel Sirlin  and Antonio Arechar  and Gordon Pennycook  and David Rand },
title = {The social media context interferes with truth discernment},
journal = {Science Advances},
volume = {9},
number = {9},
pages = {eabo6169},
year = {2023},
doi = {10.1126/sciadv.abo6169},
URL = {https://www.science.org/doi/abs/10.1126/sciadv.abo6169},
eprint = {https://www.science.org/doi/pdf/10.1126/sciadv.abo6169},
abstract = {There is widespread concern about misinformation circulating on social media. In particular, many argue that the context of social media itself may make people susceptible to the influence of false claims. Here, we test that claim by asking whether simply considering sharing news on social media reduces the extent to which people discriminate truth from falsehood when judging accuracy. In a large online experiment examining coronavirus disease 2019 (COVID-19) and political news (N\&nbsp;=\&nbsp;3157 Americans), we find support for this possibility. When judging the accuracy of headlines, participants were worse at discerning truth from falsehood if they both evaluated accuracy and indicated their sharing intentions, compared to just evaluating accuracy. These results suggest that people may be particularly vulnerable to believing false claims on social media, given that sharing is a core element of what makes social media “social.” Simply considering whether to share news on social media reduces the extent to which people discriminate truth from falsehood.}}

@inbook{socialmedias,
author = {Shen, Fuyuan},
year = {2021},
month = {10},
pages = {1-2},
title = {Introduction: Social Media as a News Source},
isbn = {9781003179580},
doi = {10.4324/9781003179580-1}
}

@article{Sherstinsky_2020,
   title={Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network},
   volume={404},
   ISSN={0167-2789},
   url={http://dx.doi.org/10.1016/j.physd.2019.132306},
   DOI={10.1016/j.physd.2019.132306},
   journal={Physica D: Nonlinear Phenomena},
   publisher={Elsevier BV},
   author={Sherstinsky, Alex},
   year={2020},
   month=mar, pages={132306} }


@misc{stephencrone2022,
	title={Monkeypox misinformation: Twitter dataset},
	url={https://www.kaggle.com/ds/2352848},
	DOI={10.34740/KAGGLE/DS/2352848},
	publisher={Kaggle},
	author={Stephen Crone},
	year={2022}
}

@misc{touvron2023llamaopenefficientfoundation,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.13971}, 
}

@misc{transformer-math-eleutherai,
	title = {Transformer Math 101},
	author = {Anthony, Quentin and Biderman, Stella and Schoelkopf, Hailey},
	url = \url{blog.eleuther.ai/transformer-math/},
	year = {2023},
}

@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}


@misc{zhang2020bertscoreevaluatingtextgeneration,
      title={BERTScore: Evaluating Text Generation with BERT}, 
      author={Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
      year={2020},
      eprint={1904.09675},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1904.09675}, 
}



