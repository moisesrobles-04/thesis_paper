\section{Conclusion}
We presented how LLMs can be used to refute health misinformation in social media. 
%Additionally, we illustrated that certain elements within a text—such as mentions, hashtags, and links—play a significant role in shaping its meaning. 
We also presented how we extracted, processed, stored, and used medical research papers with LLMs for the misinformation rebuttal. 
%Our system was implemented with Python, Postgres, Chroma, and other open-source tools. 
The research presents the performance results using health-related tweets and misinformation texts from different online sources. Our  initial results show that we can achieve an F1 score of 90\% for health-related classification and 97\% for misinformation classification. Additionally, we present that the model can refute misinformation using RAG. The misinformation rebuttal models achieve an F1 BERTScore of 82\%. Thus, the system can help health experts combat misinformation and reduce the risk of negatively impacting public health.

\section{Future Work}
Currently the system has should have more topics
Optimized vector search
LLaMa-2 and T5 can have scalability issues


%\section{Acknowledgment}
%This research is supported by the United States (US) National Library of Medicine of the National Institutes of Health (NIH) under award number R15LM012275. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH.
%
